# -*- coding: utf-8 -*-
"""Tugas NLP - Fake News Covid

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G73qOcrH44l3zz8Hm8VFqb6nNQVM1FNf

# **Loading Libraries And Data**
"""

import numpy as np
import pandas as pd
import seaborn as sns
import re
import matplotlib.pyplot as plt
import seaborn as sns

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.linear_model import SGDClassifier
import warnings
warnings.filterwarnings('ignore')

'''load training dataset'''
df = pd.read_csv('/content/data.csv')
df.head()

"""# **EDA & Cleaning**"""

print(df.info())

df['outcome'].value_counts()

# Distribusi Label
plt.figure(figsize=(8, 6))
sns.countplot(x='outcome', data=df)
plt.title('Distribusi Label Berita')
plt.xlabel('Label (0: Fake News, 1: True News)')
plt.ylabel('Jumlah Berita')
plt.show()

# Histogram
df['panjang_teks'] = df['headlines'].apply(len)
plt.figure(figsize=(10, 6))
plt.hist(df['panjang_teks'], bins=30, color='skyblue', edgecolor='black')
plt.title('Histogram Panjang Teks Berita')
plt.xlabel('Panjang Teks')
plt.ylabel('Jumlah Berita')
plt.show()

# Missing Value
plt.figure(figsize=(8, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

print(df.isnull().sum())

"""**nulls Check**"""

df.isnull().sum()

df['headlines']

"""**nltk stopwords package**"""

import nltk
nltk.download('stopwords')

"""# **Stemming**"""

stem = PorterStemmer()
def stemming(content):
    content = re.sub('[^a-zA-Z]',' ',content)
    content = content.lower()
    content = content.split()
    content = [stem.stem(word) for word in content if not word in stopwords.words('english')]
    content = ' '.join(content)
    return content
df['headlines'] = df['headlines'].apply(stemming)

"""**X & y split**"""

X = df['headlines'].values
y = df['outcome'].values

"""# **Vectoriz**"""

vectorizer = TfidfVectorizer()
vectorizer.fit(X)
X = vectorizer.transform(X)

"""**Train & Test split**"""

# prompt: buatkan untuk split data 80 dan 20

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=2)

"""# **Machine Learning Model**"""

sgd = SGDClassifier()
sgd = sgd.fit(X_train,y_train) # Now X_train and y_train are from the same split
y_tpred = sgd.predict(X_train)
y_pred = sgd.predict(X_test)

# SVM Model
svm_model = SVC()
svm_model.fit(X_train, y_train)
svm_y_pred = svm_model.predict(X_test)

# Evaluate SVM
svm_accuracy = accuracy_score(y_test, svm_y_pred)
print(f"SVM Accuracy: {svm_accuracy}")
print(f"SVM Classification Report:\n{classification_report(y_test, svm_y_pred)}")

cm = confusion_matrix(y_test, svm_y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive']) # Assuming binary classification
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for SVM')
plt.show()

"""#Confusion Matrix
####True Negative (TN) Model memprediksi berita palsu dengan benar.
####False Positive (FP) Model salah memprediksi berita asli sebagai berita palsu.
####False Negative (FN) Model salah memprediksi berita palsu sebagai berita asli.
###True Positive (TP) Model memprediksi berita asli dengan benar.
"""

# Logistic Regression Model
logreg_model = LogisticRegression()
logreg_model.fit(X_train, y_train)
logreg_y_pred = logreg_model.predict(X_test)

# Evaluate Logistic Regression
logreg_accuracy = accuracy_score(y_test, logreg_y_pred)
print(f"Logistic Regression Accuracy: {logreg_accuracy}")
print(f"Logistic Regression Classification Report:\n{classification_report(y_test, logreg_y_pred)}")

cm = confusion_matrix(y_test, logreg_y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted Negative', 'Predicted Positive'],
            yticklabels=['Actual Negative', 'Actual Positive'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix for Logistic Regression')
plt.show()

print('train score :',accuracy_score(y_train ,y_tpred ))
print('test score :',accuracy_score(y_test , y_pred))
print('con matrix :',confusion_matrix(y_test, y_pred))
print('report :',classification_report(y_test, y_pred ))

"""# **Review the results**

**Confusion Matrix**
"""

con = confusion_matrix(y_test,y_pred)
hmap =sns.heatmap(con,annot=True,fmt="d")
print ('Confusion Matrix',hmap)

"""**Classification Report**"""

labels = np.arange(2)
clf_report = classification_report(y_test,y_pred,labels=labels,target_names=('Fake News','True News'), output_dict=True)
hmap1 = sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)
print ('Classification Report',hmap1)

fake_news_headlines = ' '.join(df[df['outcome'] == 0]['headlines'])
real_news_headlines = ' '.join(df[df['outcome'] == 1]['headlines'])

fake_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(fake_news_headlines)
real_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(real_news_headlines)

plt.subplot(2, 1, 1)
plt.imshow(fake_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Fake News Headlines')

plt.tight_layout()
plt.show()

plt.subplot(2, 1, 2)
plt.imshow(real_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Real News Headlines')

plt.tight_layout()
plt.show()

# Create a DataFrame for the comparison
data = {
    'Model': ['SVM', 'Logistic Regression', 'SGD'],
    'Accuracy': [svm_accuracy, logreg_accuracy, accuracy_score(y_test, y_pred)],
    'Precision': [
        classification_report(y_test, svm_y_pred, output_dict=True)['weighted avg']['precision'],
        classification_report(y_test, logreg_y_pred, output_dict=True)['weighted avg']['precision'],
        classification_report(y_test, y_pred, output_dict=True)['weighted avg']['precision']
    ],
    'Recall': [
        classification_report(y_test, svm_y_pred, output_dict=True)['weighted avg']['recall'],
        classification_report(y_test, logreg_y_pred, output_dict=True)['weighted avg']['recall'],
        classification_report(y_test, y_pred, output_dict=True)['weighted avg']['recall']
    ],
    'F1-score': [

        classification_report(y_test, svm_y_pred, output_dict=True)['weighted avg']['f1-score'],
        classification_report(y_test, logreg_y_pred, output_dict=True)['weighted avg']['f1-score'],
        classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']
    ],
    'Vectorizer': ['TF-IDF', 'TF-IDF', 'TF-IDF']  # Assuming TF-IDF is used for all
}
comparison_df = pd.DataFrame(data)

# Display the DataFrame
comparison_df

plt.figure(figsize=(10, 6))
plt.bar(comparison_df['Model'], comparison_df['Accuracy'], color=['skyblue', 'lightcoral', 'lightgreen'])
plt.title('Perbandingan Akurasi Testing Model')
plt.xlabel('Model')
plt.ylabel('Akurasi')
plt.ylim(0.8, 1.0)
plt.show()

# prompt: Hasil EDA & insight dengan bahasa indonesia

# ... (previous code)

# Hasil EDA & Insight

# Distribusi Label Berita
# Berdasarkan plot distribusi label, terlihat proporsi antara berita palsu dan asli.
# Informasi ini penting untuk mengetahui apakah dataset seimbang atau tidak, yang berdampak pada performa model.

# Histogram Panjang Teks Berita
# Histogram menunjukkan distribusi panjang teks berita. Informasi ini bisa mengindikasikan apakah ada pola tertentu dalam panjang teks yang berhubungan dengan label berita (palsu/asli).
# Misalnya, jika berita palsu cenderung memiliki teks yang lebih pendek atau lebih panjang, hal ini bisa menjadi ciri khas.

# Missing Value
# Heatmap dan jumlah missing value untuk setiap kolom memberikan gambaran tentang kualitas data.
# Jika ada missing value yang signifikan, perlu dilakukan penanganan lebih lanjut, seperti pengisian (imputasi) atau penghapusan data.

# Stemming
# Proses stemming dilakukan untuk mengurangi kata-kata menjadi bentuk dasarnya (root words), sehingga mengurangi kompleksitas data dan meningkatkan performa model.

# Perbandingan Model
# DataFrame perbandingan model menunjukkan performa dari SVM, Logistic Regression, dan SGD Classifier.
# Kolom-kolom yang dibandingkan adalah Akurasi, Presisi, Recall, F1-score, dan Vectorizer yang digunakan.
# Model dengan nilai-nilai metrik terbaik menunjukkan model terbaik dalam mengklasifikasikan berita.

# Grafik Perbandingan Akurasi
# Grafik batang membandingkan akurasi testing model.  Grafik ini mempermudah visualisasi dan perbandingan performa antar model.

# Wordcloud
# Wordcloud untuk berita palsu dan asli memberikan gambaran kata-kata yang sering muncul dalam masing-masing kategori.
# Informasi ini memberikan insight tentang kata kunci yang bisa membedakan antara berita palsu dan asli.

# Kesimpulan Awal (Contoh)
# Berdasarkan EDA dan perbandingan model, dapat disimpulkan bahwa ... (masukkan kesimpulan berdasarkan hasil).
# Misalnya, jika model SVM memiliki akurasi tertinggi, maka dapat disimpulkan bahwa SVM adalah model terbaik untuk kasus ini.
# Perhatikan juga nilai presisi dan recall yang menunjukan kemampuan model dalam mengklasifikasikan dengan benar dan menghindari kesalahan.

# Saran Lanjutan
# 1. Analisis lebih lanjut tentang karakteristik berita palsu dan asli.
# 2. Mencoba metode preprocessing data lainnya (misalnya lemmatization).
# 3. Menguji model lain untuk perbandingan.
# 4. Melakukan hyperparameter tuning untuk meningkatkan performa model.
# 5. Menginvestigasi lebih jauh mengenai data yang salah prediksi (misalnya, memeriksa manual beberapa sampel).